{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JwFxpVXNRyEx"
      },
      "source": [
        "**Projektni zadatak**\n",
        "\n",
        "Kreirana je neuronska mreza nad Covertype skupom podataka.\n",
        "Za rad sa neuronskim mrezama je koristena bibliotrka Pytorch.\n",
        "Ukoliko se koristi Google Collab ova biblioteka je automatski\n",
        "instalirana. Za instalaciju na Linux operativnom sistemu potrebno je u komandnoj liniji pokrenuti sljedecu naredbu:\n",
        "\n",
        "\n",
        "```\n",
        "~$ pip3 install torch torchvision torchaudio\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zepTpqfLSHsc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZT2_O2A4V0o2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype #importovanje zadanog skupa podataka\n",
        "\n",
        "covtype = fetch_covtype()\n",
        "x = covtype.data #ulazne vrijednosti\n",
        "y = covtype.target #ciljane vijerdnosti"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRlSK0gcEH8"
      },
      "source": [
        "Analizirajuci Covertype skup podataka zakljucujemo da imamo ulazne podatke prikazane kao vektor duzine 54 pa iz toga zakljucujemo da su nam potrebna 54 ulazna neurona. S obzirom da je nad podacima potrebno izvrsiti klasifikaciju i posto imamo 7 klasa, onda imamo i 7 izlaznih cvorova u neuronskoj mrezi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AESeHt-odINU"
      },
      "outputs": [],
      "source": [
        "class CovertypeClasificator(nn.Module):\n",
        "  #Konstruktor\n",
        "  def __init__(self):\n",
        "    super().__init__() #pozivanje konstruktora roditeljeske klase\n",
        "\n",
        "    #input sloj\n",
        "\n",
        "    self.input_layer = nn.Linear(54, 128) #definisanje ulaznog sloja cvorova\n",
        "    self.act_input = nn.ReLU() #koristim ReLU aktivaciou funkciju zbog njene jednostavnosti i izbjegavanja problema gradijentnog nestajanja\n",
        "    #self.drop_input = nn.Dropout(p=0.25) #preko dropout-a smanjujemo overfitting tako sto se tokom treninga sa odredjenom vjerovatnocom iskljucuju cvorovi\n",
        "\n",
        "    #sloj 1\n",
        "\n",
        "    self.layer1 = nn.Linear(128, 64)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.drop1 = nn.Dropout(p=0.22) #preko dropout-a smanjujemo overfitting tako sto se tokom treninga sa odredjenom vjerovatnocom iskljucuju cvorovi\n",
        "\n",
        "    #sloj 2\n",
        "\n",
        "    self.layer2 = nn.Linear(64, 64)\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.drop2 = nn.Dropout(p=0.22)\n",
        "\n",
        "    #output sloj\n",
        "\n",
        "    self.output = nn.Linear(64, 7)\n",
        "\n",
        "  #metoda za propagaciju unaprijed (forward pass) (x(ulazni podaci) se propagira kroz slojeve mreze)\n",
        "  def forward(self, x):\n",
        "    x = self.act_input(self.input_layer(x))\n",
        "    x = self.act1(self.layer1(x))\n",
        "    x = self.drop1(x)\n",
        "    x = self.act2(self.layer2(x))\n",
        "    x = self.drop2(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S25b45Isp3GS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=23)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=23)\n",
        "#dijelimo podatke na trening, testne i validacione. Negdje je praksa da testni podaci cine od 20 do 30% ukupnog broja zadataka\n",
        "#oznacili smo shuffle kao true da bi se podaci nasumicno rasporedili prije podjele\n",
        "#kao seed za random brojeve smo izabrali konkretan broj da bismo uvijek imali istu sekvencu nasumicnih brojeva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WTU4w5jbsK4J"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Bitno je da znamo da su nam podaci iz sklearn.datasets dati kao numpy nizovi (np.ndarray) a Pytorch radi sa\n",
        "#tenzorima pa je potrebno konvertovati ulazne podatke.\n",
        "\n",
        "x_train_t = torch.tensor(x_train).float()\n",
        "x_test_t = torch.tensor(x_test).float()\n",
        "x_val_t = torch.tensor(x_val).float()\n",
        "y_train_t = torch.tensor(y_train - 1).long() #Neophodno je da stavimo y_train - 1 jer klase idu od 0 do 6 a ne od 1 do 7\n",
        "y_test_t = torch.tensor(y_test - 1).long() #long je pogodno koristiti kod klasifikacije\n",
        "y_val_t = torch.tensor(y_val - 1).long()\n",
        "\n",
        "#TensorDataset se koristi da se ulazni podaci i ciljne klase grupisu zajedno u jedan dataset\n",
        "train_dataset = TensorDataset(x_train_t, y_train_t) #grupisemo trening podatke\n",
        "test_dataset = TensorDataset(x_test_t, y_test_t) #grupisemo test podatke\n",
        "val_dataset = TensorDataset(x_val_t, y_val_t) #grupisemo validacione podatke\n",
        "\n",
        "#Klasa Dataloader se koristi za iteriranje kroz trening i test datasetove.\n",
        "#Podaci se grupisu u batcheve(skupovi uzoraka iz dataset-a koji se koristi za treniranje\n",
        "#ili evaluaciju modela) određene velicine.\n",
        "#batch_size je postavljen na 40 tako da ce svaka iteracija imati 40 uzoraka\n",
        "#shuffle u train loader-u je stavljen kao True tako da ce se podaci mijesati prije\n",
        "#svake epohe. Za test i validacioni skup nije neophodno sshuffle staviti true jer se testiranje vrsi nad nevidjenim podacima\n",
        "train_loader = DataLoader(train_dataset, batch_size=40, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=40)\n",
        "val_loader = DataLoader(val_dataset, batch_size=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z6OYLAJ1oTi",
        "outputId": "32120ad1-5592-4d2b-9913-83b6c4130859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\") # koristimo gpu samo ako je dostupan, inace koristimo cpu\n",
        "print(device)\n",
        "net = CovertypeClasificator().to(device) #kreieamo mrezu i premjestimo je na izabrani uredjaj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hdft5P1n5JQu"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss() #funkcija greske koja daje dobre rezultate za klasifikaciju\n",
        "EPOCHS = 35 #epoha je jedan prelazak kroz kompletan skup trening podataka\n",
        "\n",
        "#optimizator se koristi za azuriranje podataka mreze tokom treninga\n",
        "#prvi argument je skup parametara mreže koje će optimizator azurirati\n",
        "#drugi argument predstavlja stopu ucenja dok treci predstavlja faktor\n",
        "#regulacije koji sprjecava preveliko prilagodjavanje trening podacima\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "#optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
        "\n",
        "#test_model(net, loss_fn, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t0e9_BeQFloO"
      },
      "outputs": [],
      "source": [
        "# TRAIN FUNKCIJA\n",
        "def train_model(net, loss_fn, optimizer, EPOCHS):\n",
        "  net.train()  # stavljamo mrežu u mod rada za trening\n",
        "  for i in range(EPOCHS): #Vrsimo treniranje onoliko puta koliko je epoha definisano\n",
        "    print(f\"Izvrsavanje epohe {i + 1}\") #Kontrolni ispis da znamo da se izvrsava posto trening traje dugo (Nema nikakvog uticaja na logiku)\n",
        "    for x, y in train_loader: #prolazimo kroz trening podatke\n",
        "      x = x.to(device) #Prebacujemo podatke na dostupan uredjaj\n",
        "      y = y.to(device)\n",
        "      preds = net(x) #dobijanje predikcije koriscenjem mreze i ulaznih podataka x\n",
        "      loss = loss_fn(preds, y) #Izracunavanje gubitka izmedju predikcija i ciljnih vrijednosti koriscenjem funkcije\n",
        "      optimizer.zero_grad() #postavljanje gradijenata svih parametara mreze na nulu\n",
        "      loss.backward() #izračunavanje gradijenta gubitka loss unazad kroz mrežu odnosno narodski receno propagacija unazad\n",
        "      optimizer.step() #optimizacijski korak - azuriranje parametara na osnovu dobijenih gradijenata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UyO-R_Ghuu3i"
      },
      "outputs": [],
      "source": [
        "def train_model_with_early_stopping(net, loss_fn, optimizer, train_loader, val_loader, EPOCHS): #implementacija druge tacke - rano stopiranje tokom treninga\n",
        "  best_val_loss = float('inf') #varijabla za pracenje najbolje greske, u pocetku joj je dodjeljeno +beskonacno\n",
        "  increasing_epochs = 0 #Brojac uzastopnih epoha u kojima greska raste\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    net.train()\n",
        "    train_loss = 0 #vrijednost gubitka tokom treninga\n",
        "    for x, y in train_loader: #sve identicno kao kod obicnog treninga\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      preds = net(x)\n",
        "      loss = loss_fn(preds, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader) #izracunavanje prosjecne greske po uzorku u trening skupu\n",
        "\n",
        "    net.eval() #stavljanje mreze u evalucioni mod\n",
        "    total_val_loss = 0 #ukupan gubitak nad validacionim skupom\n",
        "    with torch.no_grad(): #ne racunamo gradijent jer nam on nije potreban tokom testa i validacije\n",
        "      for x_val, y_val in val_loader: #sljedeci blok koda je identican onom za trening s tim da se ne racuna gradijent i ne propagira greska unazad (ne vrsi se trening mreze)\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        preds_val = net(x_val)\n",
        "        val_loss = loss_fn(preds_val, y_val)\n",
        "        total_val_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader) #izracunavanje prosjecne greske u validacionom skupu\n",
        "    print(f'Epoha {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}') #Kontrolni ispis\n",
        "\n",
        "    if best_val_loss > val_loss: #provjeravamo da li se greska na validacionom skupu povecava\n",
        "      best_val_loss = val_loss #imamo novu najmanju gresku\n",
        "      increasing_epochs = 0 #ukoliko je brojac bio uvecavan, restartujemo ga\n",
        "    else:\n",
        "      increasing_epochs += 1 #ukoliko greska raste, inkrementujemo brojac\n",
        "\n",
        "    if increasing_epochs > 2: #ukoliko je prekoracen broj dozvoljenih epoha sa greskom\n",
        "      print(\"Early stopping - zavrsava se trening\")\n",
        "      break #obustavljamo dalje izvrsavanje epoha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uVd50Ks1XroD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "import warnings\n",
        "\n",
        "def test_model(net, loss_fn, test_loader): #definisemo funkciju za testiranje modela\n",
        "    total_loss = 0 #ovu varijablu cemo koristiti za sumiranje ukupnih gubitaka\n",
        "    net.eval()\n",
        "    y_true = [] #inicijalizacija liste za stvarne vrijednosti\n",
        "    y_pred = [] #inicijalizacija liste za predvidjene vrijednosti, koristicemo ih za racunanje metrika\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = net(x)\n",
        "            _, predicted = torch.max(preds.data, 1) #Koristimo _ da bismo ignorisali povratnu vrijednost - indeks maksimalne vrijednosti\n",
        "                                                    #jer nam on nije potreban. Koristimo funkciju max jer nam treba najveca vjerovatnoca pjavljivanja klase\n",
        "            loss = loss_fn(preds, y) #racunanje gubitka uz pomoc predikcija i stvarnih vrijednosti\n",
        "            total_loss += loss.item() #akumuliranje pojedinacnih gubitaka iz test skupa\n",
        "            y_true.extend(y.cpu().numpy()) #prosirujemo liste vrijednostima ali ih prvo pretvaramo iz tenzora u niz jer izabrane funkcije za metrike rade sa nizovima\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(total_loss / len(test_loader)) #prosjecan gubitak nad testnim skupom podataka\n",
        "    accuracy = accuracy_score(y_true, y_pred) #racunanje tacnosti\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division = 0.0) #racunanje preciznosti\n",
        "    recall = recall_score(y_true, y_pred, average='macro') #racunanje odziva\n",
        "\n",
        "    print(f'Tacnost: {accuracy:.2f}')\n",
        "    print(f'Preciznost: {precision:.2f}')\n",
        "    print(f'Ukupan odziv: {recall:.2f}')\n",
        "\n",
        "    # Racunanje odziva za svaku klasu posebno\n",
        "    class_recall = recall_score(y_true, y_pred, average=None)\n",
        "    for i, recall in enumerate(class_recall):\n",
        "        print(f'Odziv za klasu {i}: {recall:.2f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1tGHQ5rSzTp",
        "outputId": "e8c00a31-3037-43dc-9b1d-82408a685ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21.728117665530302\n",
            "Tacnost: 0.01\n",
            "Preciznost: 0.03\n",
            "Ukupan odziv: 0.13\n",
            "Odziv za klasu 0: 0.00\n",
            "Odziv za klasu 1: 0.00\n",
            "Odziv za klasu 2: 0.12\n",
            "Odziv za klasu 3: 0.78\n",
            "Odziv za klasu 4: 0.00\n",
            "Odziv za klasu 5: 0.00\n",
            "Odziv za klasu 6: 0.00\n"
          ]
        }
      ],
      "source": [
        "#train_model(net, loss_fn, optimizer, EPOCHS)\n",
        "test_model(net, loss_fn, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fMSjCCEyO4J",
        "outputId": "99bb5224-7316-459f-8ab1-1bdf3f8e22ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoha 1: Train Loss: 0.6620, Val Loss: 0.7134\n",
            "Epoha 2: Train Loss: 0.6569, Val Loss: 0.6227\n",
            "Epoha 3: Train Loss: 0.6522, Val Loss: 0.6195\n",
            "Epoha 4: Train Loss: 0.6512, Val Loss: 0.6182\n",
            "Epoha 5: Train Loss: 0.6500, Val Loss: 0.6467\n",
            "Epoha 6: Train Loss: 0.6502, Val Loss: 0.6198\n",
            "Epoha 7: Train Loss: 0.6459, Val Loss: 0.6050\n",
            "Epoha 8: Train Loss: 0.6459, Val Loss: 0.6181\n",
            "Epoha 9: Train Loss: 0.6426, Val Loss: 0.6101\n",
            "Epoha 10: Train Loss: 0.6423, Val Loss: 0.6271\n",
            "Early stopping - zavrsava se trening\n"
          ]
        }
      ],
      "source": [
        "train_model_with_early_stopping(net, loss_fn, optimizer, train_loader, val_loader, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNkDig4aXpHn",
        "outputId": "b78f8ae3-3bf8-4852-ec9b-15457f4034fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6271645752672057\n",
            "Tacnost: 0.73\n",
            "Preciznost: 0.75\n",
            "Ukupan odziv: 0.51\n",
            "Odziv za klasu 0: 0.63\n",
            "Odziv za klasu 1: 0.90\n",
            "Odziv za klasu 2: 0.72\n",
            "Odziv za klasu 3: 0.57\n",
            "Odziv za klasu 4: 0.13\n",
            "Odziv za klasu 5: 0.45\n",
            "Odziv za klasu 6: 0.18\n"
          ]
        }
      ],
      "source": [
        "test_model(net, loss_fn, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
